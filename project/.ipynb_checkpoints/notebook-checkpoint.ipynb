{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13f5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from net import Net\n",
    "from net2 import Net2\n",
    "from dataset import create_data_loader, split_train_val, getUpperIndices, addASpace\n",
    "\n",
    "import os\n",
    "import string\n",
    "\n",
    "#to do: \n",
    "    #shuffle test and train data\n",
    "    #see if vocab actually gets updated (it seems to be but i dont believe it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e7b6beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8f7e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "#parameters:\n",
    "numEpochs = 10\n",
    "batchSize = 1\n",
    "learningRate = 0.01\n",
    "\n",
    "paddingValue = 0\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print('device:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1fe342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['_PADDING_']\n",
    "\n",
    "\n",
    "# Turn string into tensor of ints\n",
    "def tensorConvert(string):\n",
    "    # runtime can be improved if we find a way to convert tensor using tensor / numpy methods of some sort\n",
    "    # only thing is i wouldnt know how to do this with a vocab though\n",
    "\n",
    "    output = []\n",
    "\n",
    "    tokenize = string.split()\n",
    "    for token in tokenize:\n",
    "        if token not in vocab:\n",
    "            vocab.append(token)\n",
    "\n",
    "        output.append(vocab.index(token))\n",
    "        \n",
    "        #print('\\nappended',token,'to vocab!')\n",
    "\n",
    "    output = torch.LongTensor(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3403bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Classes: 50\n",
      "classes: ['AaronPressman', 'AlanCrosby', 'AlexanderSmith', 'BenjaminKangLim', 'BernardHickey']\n"
     ]
    }
   ],
   "source": [
    "# get list of authors\n",
    "classes = []\n",
    "rootdir = 'Data/C50'\n",
    "for it in os.scandir(rootdir): #scan subdirectory and append each element to list of classes\n",
    "    if it.is_dir():\n",
    "        author = it.path.replace(rootdir + \"\\\\\" , '') #remove 'C50train\\' from string\n",
    "        \n",
    "        #if author == \"DarrenSchuettler\": #this is an early stop\n",
    "            #break\n",
    "            \n",
    "        classes.append(author) \n",
    "\n",
    "print('Num Classes:',len(classes))\n",
    "print('classes:',classes[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd639d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 5000\n"
     ]
    }
   ],
   "source": [
    "#data:\n",
    "length = sum([len(files) for r, d, files in os.walk(\"Data/C50\")])\n",
    "print('Number of files:', length) #this is kinda inaccurate now with the extra csvs and main file\n",
    "\n",
    "data = []\n",
    "\n",
    "def gatherData(path):\n",
    "    #0 = train, 1 = test\n",
    "    address = path + \"/C50\"\n",
    "\n",
    "        \n",
    "    prelude = len(address)\n",
    "    \n",
    "    for r, d, files in os.walk(address):\n",
    "        \n",
    "        #print here to show progress, warning, a shit load of print statements\n",
    "        \n",
    "        author = r[(prelude+1):]\n",
    "\n",
    "        if author == \"\":\n",
    "            continue\n",
    "            \n",
    "        #EARLY STOP FOR DEVELOPMENT PURPOSES (cuz going through every author takes an ass load time)\n",
    "        if author == \"DarrenSchuettler\": #AlexanderSmith\n",
    "            break\n",
    "        \n",
    "        #print('\\nr:',r)\n",
    "        print('\\nAuthor:', author)\n",
    "        ratio = classes.index(author) / len(classes)\n",
    "        print(round(ratio * 100,2), '% there.')\n",
    "\n",
    "        for file in files:\n",
    "            address = r + '/' + file\n",
    "\n",
    "            with open(address, 'r') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            convert = tensorConvert(content)\n",
    "            \n",
    "            #print('vocab length:',len(vocab))\n",
    "            #print('sample:',convert[:5])\n",
    "            \n",
    "            authorIdx = classes.index(author)\n",
    "            \n",
    "            item = [authorIdx, convert]\n",
    "            #print('item:',item)\n",
    "            \n",
    "            data.append(item)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6c8c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Author: AaronPressman\n",
      "0.0 % there.\n",
      "\n",
      "Author: AlanCrosby\n",
      "2.0 % there.\n",
      "\n",
      "Author: AlexanderSmith\n",
      "4.0 % there.\n",
      "\n",
      "Author: BenjaminKangLim\n",
      "6.0 % there.\n",
      "\n",
      "Author: BernardHickey\n",
      "8.0 % there.\n",
      "\n",
      "Author: BradDorfman\n",
      "10.0 % there.\n"
     ]
    }
   ],
   "source": [
    "gatherData('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f108eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,   1,  19,  20,  21,  22,  23,  24,  16,  25,  26,\n",
      "         27,  28,  16,   2,  29,  16,  30,  31,  11,  32,  33,  34,  11,  35,\n",
      "         36,  37,  38,  39,  40,   6,  41,  15,  42,  43,   1,  44,  35,  45,\n",
      "         46,  47,  48,  49,  50,  51,  52,  35,  53,  54,  55,  56,  28,  16,\n",
      "         57,  58,  50,  11,  59,  60,   2,  61,  62,  63,  64,   1,  65,  32,\n",
      "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         80,  81,  35,  27,  28,  16,   2,  82,  83,  84,  22,  85,  86,  87,\n",
      "         15,  16,  88,  89,  90,  91,  15,  92,  93,   2,  61,  62,  94,  72,\n",
      "         35,  95,  96,  97,  16,  98,  11,  99, 100,  51,  11, 101, 102, 103,\n",
      "        104, 105, 106,  16, 107, 108,   2,  67,  97, 109, 110,  35,  53, 111,\n",
      "         75, 112, 113,  24, 114, 115,  11, 116, 117, 118, 119,  34, 120, 121,\n",
      "        122, 123,  35, 124,  69, 125, 126, 127,  15, 128, 129, 112, 130,  25,\n",
      "         15,  16, 131,  16, 107, 132,  61,  67,  69,  16, 133,  65,  32,  71,\n",
      "         72, 134, 116, 135, 136,  38, 137,  97, 138, 139, 140, 141, 142,   1,\n",
      "        143,   2, 144,  16, 145, 146,  29,  16, 147,  15,  36,   2, 148, 149,\n",
      "        150, 151, 152,  50, 153, 154,   2, 155, 156, 103, 157, 158, 159, 160,\n",
      "         80, 161, 162, 163, 149, 150, 164, 165, 154, 166, 167, 116,  16, 168,\n",
      "        140, 169, 170, 171, 172, 173, 174, 154, 175,  63, 176,  16, 145, 177,\n",
      "        178, 179,  51, 180, 181, 182, 183, 184,   3, 185, 186,  11,  35, 181,\n",
      "        154, 187, 188, 189, 190, 154, 191, 192,  26, 193, 194,  97, 195, 196,\n",
      "        197, 198, 199, 200,  63, 201,   1,  21, 202, 203, 204,  24, 205, 114,\n",
      "        206, 207,  97, 208,  35, 209,  15,  16,  61,  62, 210])]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "\n",
    "#for item in data:\n",
    "    #print(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b3f42ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082\n",
      "319\n"
     ]
    }
   ],
   "source": [
    "#find maxLength for padding purposes\n",
    "maxLength = 0\n",
    "\n",
    "for item in data:\n",
    "    tensor = item[1]\n",
    "    length = len(tensor)\n",
    "    if length > maxLength:\n",
    "        maxLength = length\n",
    "        \n",
    "print(maxLength)\n",
    "print(len(data[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb6426c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, tensor([1., 2., 3.,  ..., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "def padTensor(tensor):\n",
    "    length = len(tensor)\n",
    "\n",
    "    pad = torch.ones((maxLength - length,))\n",
    "    pad = pad * paddingValue\n",
    "    #print('pad:',pad)\n",
    "\n",
    "    newTensor = torch.cat((tensor, pad),0)\n",
    "    \n",
    "    return newTensor\n",
    "    \n",
    "for item in data:\n",
    "    tensor = item[1]\n",
    "    newTensor = padTensor(tensor)\n",
    "    \n",
    "    item[1] = newTensor\n",
    "\n",
    "item = data[0]\n",
    "print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de3bd207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data: 600\n",
      "Length of partitions: 480 60 60\n",
      "Sum: 600\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset\n",
    "trainData, valData, testData = split_train_val(data, props=[0.8, 0.1, 0.1])\n",
    "\n",
    "print('Length of data:', len(data))\n",
    "print('Length of partitions:',len(trainData), len(valData), len(testData))\n",
    "print('Sum:',len(trainData) + len(valData) + len(testData))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a07ae59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': tensor([[ 286.,   16., 1127.,  ...,    0.,    0.,    0.]]),\n",
       " 'target': tensor([0])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLoader = create_data_loader(trainData, \n",
    "                                      batchSize,\n",
    "                                      shuffle=True)\n",
    "valLoader = create_data_loader(valData, \n",
    "                                    batchSize,\n",
    "                                    shuffle=True)\n",
    "testLoader = create_data_loader(testData, \n",
    "                                    batchSize,\n",
    "                                    shuffle=True)\n",
    "\n",
    "next(iter(trainLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "238bf0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputSize: 1082\n"
     ]
    }
   ],
   "source": [
    "#insert model here, need to get numbers for these\n",
    "#inputSize = len(vocab) #not sure if its supposed to be maxLength or len(vocab)\n",
    "inputSize = maxLength\n",
    "hiddenSize = 512\n",
    "outputSize = len(classes)\n",
    "\n",
    "#net = Net(inputSize, hiddenSize, outputSize).to(device)\n",
    "net = Net2(inputSize, hiddenSize, outputSize).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.NLLLoss() #apparently NLL is good for multiclass classification\n",
    "optimizer = optim.AdamW(net.parameters(), lr=learningRate)\n",
    "\n",
    "print('inputSize:',inputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66e4f00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: \t Training Loss: 809.6557249966943 \t Validation Loss: 0.03409546216328939\n",
      "\tValidation Loss Decreased(inf--->2.045728) \t Saving The Model\n",
      "\n",
      "Epoch 2: \t Training Loss: 295.751554206262 \t Validation Loss: 0.02910375197728475\n",
      "\tValidation Loss Decreased(2.045728--->1.746225) \t Saving The Model\n",
      "\n",
      "Epoch 3: \t Training Loss: 51.404752347494124 \t Validation Loss: 0.031505370140075685\n",
      "\n",
      "Epoch 4: \t Training Loss: 390.21542462125655 \t Validation Loss: 0.03032662272453308\n",
      "\n",
      "Epoch 5: \t Training Loss: 1115.4271482380727 \t Validation Loss: 0.030556674798329672\n",
      "\n",
      "Epoch 6: \t Training Loss: 22958.14172873472 \t Validation Loss: 0.02942627271016439\n",
      "\n",
      "Epoch 7: \t Training Loss: 2424.45007648319 \t Validation Loss: 0.03277819156646729\n",
      "\n",
      "Epoch 8: \t Training Loss: nan \t Validation Loss: nan\n",
      "\n",
      "Epoch 9: \t Training Loss: nan \t Validation Loss: nan\n",
      "\n",
      "Epoch 10: \t Training Loss: nan \t Validation Loss: nan\n"
     ]
    }
   ],
   "source": [
    "#start training + print accuracy\n",
    "#i see no reason to split any of this up into multiple cells but feel free to do so if there is one\n",
    "\n",
    "#xLen = next(iter(trainLoader))['input'].shape[1]\n",
    "xLen = 1\n",
    "\n",
    "hidden = net.init_hidden(xLen)\n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "for e in range(numEpochs):\n",
    "    #training loop\n",
    "    train_loss = 0.0\n",
    "    net.train()\n",
    "\n",
    "    for item in trainLoader:\n",
    "        data = item['input']\n",
    "        label = item['target']\n",
    "\n",
    "        #print('label:',label)\n",
    "        \n",
    "        data, label = data.to(device), label.to(device)\n",
    "        \n",
    "        #data = data.long()\n",
    "        #label = label.long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = net(data, hidden)\n",
    "        \n",
    "        hidden = hidden.detach()\n",
    "        #output = net(data)\n",
    "        \n",
    "        #print('output:',output)\n",
    "        #print('output shape:',output.shape)\n",
    "        \n",
    "        #print('output:',torch.unsqueeze(output[0], 0))\n",
    "        #print('output shape:',torch.unsqueeze(output[0], 0).shape)\n",
    "        \n",
    "        #output = torch.unsqueeze(output[0], 0) \n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    #validation loop\n",
    "    valid_loss = 0.0\n",
    "    net.eval()  # Optional when not using Model Specific layer\n",
    "    for item in valLoader:\n",
    "        data = item['input']\n",
    "        label = item['target']\n",
    "        \n",
    "        #print('label:',label)\n",
    "        \n",
    "        data, label = data.to(device), label.to(device)\n",
    "        \n",
    "        #data = data.long()\n",
    "        #label = label.long()\n",
    "\n",
    "        #output = net(data)\n",
    "        output, hidden = net(data, hidden)\n",
    "        \n",
    "        output = torch.unsqueeze(output[0], 0)\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        valid_loss = loss.item() * data.size(0)\n",
    "\n",
    "    print(\n",
    "        f'\\nEpoch {e + 1}: \\t Training Loss: {train_loss / len(trainLoader)} \\t Validation Loss: {valid_loss / len(valLoader)}')\n",
    "\n",
    "    #save model if validation loss decreases\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'\\tValidation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(net.state_dict(), 'Models/saved_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71fbc674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "output: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]])\n",
      "Accuracy for class AaronPressman is: 100.0 %\n",
      "Accuracy for class AlanCrosby is: 0.0 %\n",
      "Accuracy for class AlexanderSmith is: 0.0 %\n",
      "Accuracy for class BenjaminKangLim is: 0.0 %\n",
      "Accuracy for class BernardHickey is: 0.0 %\n",
      "Accuracy for class BradDorfman is: 0.0 %\n",
      "\n",
      "Total Accuracy: 15.0 %\n"
     ]
    }
   ],
   "source": [
    "#test loop\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "totalPred = 0\n",
    "correctPred = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for item in testLoader:\n",
    "\n",
    "        data = item['input']\n",
    "        label = item['target']\n",
    "        \n",
    "        #print(label)\n",
    "        \n",
    "        output, hidden = net(data, hidden)\n",
    "\n",
    "        #print('output:',output)\n",
    "        prediction = torch.argmax(output)\n",
    "\n",
    "        #print(prediction)\n",
    "        \n",
    "        #print('\\nlabel:',label)\n",
    "        #print('prediction:',prediction)\n",
    "        if label == prediction:\n",
    "            \n",
    "            correct_pred[classes[label]] += 1\n",
    "            correctPred += 1\n",
    "            \n",
    "        total_pred[classes[label]] += 1\n",
    "        totalPred += 1\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    if total_pred[classname] == 0:\n",
    "        continue\n",
    "    \n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))\n",
    "    \n",
    "print('\\nTotal Accuracy:', round((correctPred / totalPred) * 100, 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9ac974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
