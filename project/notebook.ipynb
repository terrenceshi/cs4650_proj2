{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13f5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from net import Net\n",
    "from dataset import create_data_loader, split_train_val, getUpperIndices, addASpace\n",
    "\n",
    "import os\n",
    "import string\n",
    "\n",
    "#to do: \n",
    "    #shuffle test and train data\n",
    "    #see if vocab actually gets updated (it seems to be but i dont believe it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e7b6beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8f7e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "#parameters:\n",
    "numEpochs = 10\n",
    "batchSize = 1\n",
    "learningRate = 0.001\n",
    "\n",
    "paddingValue = 0\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print('device:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1fe342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['_PADDING_']\n",
    "\n",
    "\n",
    "# Turn string into tensor of ints\n",
    "def tensorConvert(string):\n",
    "    # runtime can be improved if we find a way to convert tensor using tensor / numpy methods of some sort\n",
    "    # only thing is i wouldnt know how to do this with a vocab though\n",
    "\n",
    "    output = []\n",
    "\n",
    "    tokenize = string.split()\n",
    "    for token in tokenize:\n",
    "        if token not in vocab:\n",
    "            vocab.append(token)\n",
    "\n",
    "        output.append(vocab.index(token))\n",
    "        \n",
    "        #print('\\nappended',token,'to vocab!')\n",
    "\n",
    "    output = torch.LongTensor(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3403bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Classes: 50\n",
      "classes: ['AaronPressman', 'AlanCrosby', 'AlexanderSmith', 'BenjaminKangLim', 'BernardHickey']\n"
     ]
    }
   ],
   "source": [
    "# get list of authors\n",
    "classes = []\n",
    "rootdir = 'Data/C50'\n",
    "for it in os.scandir(rootdir): #scan subdirectory and append each element to list of classes\n",
    "    if it.is_dir():\n",
    "        classes.append(it.path.replace(rootdir + \"\\\\\" , '')) #remove 'C50train\\' from string\n",
    "\n",
    "print('Num Classes:',len(classes))\n",
    "print('classes:',classes[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd639d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 5000\n"
     ]
    }
   ],
   "source": [
    "#data:\n",
    "length = sum([len(files) for r, d, files in os.walk(\"Data/C50\")])\n",
    "print('Number of files:', length)\n",
    "\n",
    "data = []\n",
    "\n",
    "def gatherData(path):\n",
    "    #0 = train, 1 = test\n",
    "    address = path + \"/C50\"\n",
    "\n",
    "        \n",
    "    prelude = len(address)\n",
    "    \n",
    "    for r, d, files in os.walk(address):\n",
    "        \n",
    "        #print here to show progress, warning, a shit load of print statements\n",
    "        \n",
    "        author = r[(prelude+1):]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if author == \"\":\n",
    "            continue\n",
    "        \n",
    "        #print('\\nr:',r)\n",
    "        print('\\nAuthor:', author)\n",
    "        ratio = classes.index(author) / len(classes)\n",
    "        print(ratio * 100, '% there.')\n",
    "            \n",
    "        #EARLY STOP FOR DEVELOPMENT PURPOSES (cuz going through every author takes an ass load time)\n",
    "        if author == \"DarrenSchuettler\":\n",
    "            break\n",
    "\n",
    "        for file in files:\n",
    "            address = r + '/' + file\n",
    "\n",
    "            with open(address, 'r') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            convert = tensorConvert(content)\n",
    "            \n",
    "            #print('vocab length:',len(vocab))\n",
    "            #print('sample:',convert[:5])\n",
    "            \n",
    "            authorIdx = classes.index(author)\n",
    "            \n",
    "            item = [authorIdx, convert]\n",
    "            #print('item:',item)\n",
    "            \n",
    "            data.append(item)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6c8c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Author: AaronPressman\n",
      "0.0 % there.\n",
      "\n",
      "Author: AlanCrosby\n",
      "2.0 % there.\n",
      "\n",
      "Author: AlexanderSmith\n",
      "4.0 % there.\n",
      "\n",
      "Author: BenjaminKangLim\n",
      "6.0 % there.\n",
      "\n",
      "Author: BernardHickey\n",
      "8.0 % there.\n",
      "\n",
      "Author: BradDorfman\n",
      "10.0 % there.\n",
      "\n",
      "Author: DarrenSchuettler\n",
      "12.0 % there.\n"
     ]
    }
   ],
   "source": [
    "gatherData('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f108eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n",
      "[0, tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,   1,  19,  20,  21,  22,  23,  24,  16,  25,  26,\n",
      "         27,  28,  16,   2,  29,  16,  30,  31,  11,  32,  33,  34,  11,  35,\n",
      "         36,  37,  38,  39,  40,   6,  41,  15,  42,  43,   1,  44,  35,  45,\n",
      "         46,  47,  48,  49,  50,  51,  52,  35,  53,  54,  55,  56,  28,  16,\n",
      "         57,  58,  50,  11,  59,  60,   2,  61,  62,  63,  64,   1,  65,  32,\n",
      "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         80,  81,  35,  27,  28,  16,   2,  82,  83,  84,  22,  85,  86,  87,\n",
      "         15,  16,  88,  89,  90,  91,  15,  92,  93,   2,  61,  62,  94,  72,\n",
      "         35,  95,  96,  97,  16,  98,  11,  99, 100,  51,  11, 101, 102, 103,\n",
      "        104, 105, 106,  16, 107, 108,   2,  67,  97, 109, 110,  35,  53, 111,\n",
      "         75, 112, 113,  24, 114, 115,  11, 116, 117, 118, 119,  34, 120, 121,\n",
      "        122, 123,  35, 124,  69, 125, 126, 127,  15, 128, 129, 112, 130,  25,\n",
      "         15,  16, 131,  16, 107, 132,  61,  67,  69,  16, 133,  65,  32,  71,\n",
      "         72, 134, 116, 135, 136,  38, 137,  97, 138, 139, 140, 141, 142,   1,\n",
      "        143,   2, 144,  16, 145, 146,  29,  16, 147,  15,  36,   2, 148, 149,\n",
      "        150, 151, 152,  50, 153, 154,   2, 155, 156, 103, 157, 158, 159, 160,\n",
      "         80, 161, 162, 163, 149, 150, 164, 165, 154, 166, 167, 116,  16, 168,\n",
      "        140, 169, 170, 171, 172, 173, 174, 154, 175,  63, 176,  16, 145, 177,\n",
      "        178, 179,  51, 180, 181, 182, 183, 184,   3, 185, 186,  11,  35, 181,\n",
      "        154, 187, 188, 189, 190, 154, 191, 192,  26, 193, 194,  97, 195, 196,\n",
      "        197, 198, 199, 200,  63, 201,   1,  21, 202, 203, 204,  24, 205, 114,\n",
      "        206, 207,  97, 208,  35, 209,  15,  16,  61,  62, 210])]\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0][1]))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b3f42ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082\n",
      "319\n"
     ]
    }
   ],
   "source": [
    "#find maxLength for padding purposes\n",
    "maxLength = 0\n",
    "\n",
    "for item in data:\n",
    "    tensor = item[1]\n",
    "    length = len(tensor)\n",
    "    if length > maxLength:\n",
    "        maxLength = length\n",
    "        \n",
    "print(maxLength)\n",
    "print(len(data[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb6426c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, tensor([1., 2., 3.,  ..., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "def padTensor(tensor):\n",
    "    length = len(tensor)\n",
    "\n",
    "    pad = torch.ones((maxLength - length,))\n",
    "    pad = pad * paddingValue\n",
    "    #print('pad:',pad)\n",
    "\n",
    "    newTensor = torch.cat((tensor, pad),0)\n",
    "    \n",
    "    return newTensor\n",
    "    \n",
    "for item in data:\n",
    "    tensor = item[1]\n",
    "    newTensor = padTensor(tensor)\n",
    "    \n",
    "    item[1] = newTensor\n",
    "\n",
    "item = data[0]\n",
    "print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de3bd207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data: 600\n",
      "Length of partitions: 480 60 60\n",
      "Sum: 600\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset\n",
    "trainData, valData, testData = split_train_val(data, props=[0.8, 0.1, 0.1])\n",
    "\n",
    "print('Length of data:', len(data))\n",
    "print('Length of partitions:',len(trainData), len(valData), len(testData))\n",
    "print('Sum:',len(trainData) + len(valData) + len(testData))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a07ae59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': tensor([[1.0000e+00, 3.1140e+03, 1.5000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " 'target': tensor([0])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLoader = create_data_loader(trainData, \n",
    "                                      batchSize,\n",
    "                                      shuffle=True)\n",
    "valLoader = create_data_loader(testData, \n",
    "                                    batchSize,\n",
    "                                    shuffle=True)\n",
    "\n",
    "next(iter(trainLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "238bf0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputSize: 1082\n"
     ]
    }
   ],
   "source": [
    "#insert model here, need to get numbers for these\n",
    "#inputSize = len(vocab) #not sure if its supposed to be maxLength or len(vocab)\n",
    "inputSize = maxLength\n",
    "hiddenSize = 512\n",
    "outputSize = len(classes)\n",
    "\n",
    "net = Net(inputSize, hiddenSize, outputSize).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=learningRate)\n",
    "\n",
    "print('inputSize:',inputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e4f00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: torch.Size([1, 1082])\n",
      "test: tensor([[   1, 3114,   15,  ...,    0,    0,    0]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10580/2348246351.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\GitHub\\cs4650_proj2\\project\\net.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#.view(1, 1, -1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m#print('\\ntest:',self.encoder(x).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2042\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "#start training + print accuracy\n",
    "#i see no reason to split any of this up into multiple cells but feel free to do so if there is one\n",
    "\n",
    "hidden = net.init_hidden()\n",
    "\n",
    "for e in range(numEpochs):\n",
    "    #training loop\n",
    "    train_loss = 0.0\n",
    "    net.train()\n",
    "    for item in trainLoader:\n",
    "        data = item['input']\n",
    "        label = item['target']\n",
    "        \n",
    "        data = data.long()\n",
    "\n",
    "        \n",
    "        #print('data shape:',data.shape)\n",
    "        #print('data:',data)\n",
    "        \n",
    "        data, label = data.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = net(data, hidden)\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    #validation loop\n",
    "    valid_loss = 0.0\n",
    "    net.eval()  # Optional when not using Model Specific layer\n",
    "    for item in validLoader:\n",
    "        data = item['input']\n",
    "        label = item['target']\n",
    "        \n",
    "        data = data.long()\n",
    "        \n",
    "        data, label = data.to(device), label.to(device)\n",
    "\n",
    "        output = net(data)\n",
    "        loss = criterion(output, label)\n",
    "        valid_loss = loss.item() * data.size(0)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {e + 1} \\t\\t Training Loss: {train_loss / len(trainLoader)} \\t\\t Validation Loss: {valid_loss / len(validLoader)}')\n",
    "\n",
    "    #save model if validation loss decreases\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(net.state_dict(), 'Models/saved_model.pth')\n",
    "\n",
    "#test loop\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        data = item['input']\n",
    "        label = item['target']\n",
    "        \n",
    "        data = data.long()\n",
    "        \n",
    "        outputs = net(data)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        if label == prediction:\n",
    "            correct_pred[classes[label]] += 1\n",
    "        total_pred[classes[label]] += 1\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
